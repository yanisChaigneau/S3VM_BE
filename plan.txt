Première partie d'introduction sur l'apprentissage semi-supervisé général pour en faire
comprendre l'intuition
--> petits graphiques et cellules de codes pour comprendre en quoi ca consiste
(une partie de labelled data et une partie non) et comment on peut faire pour y 
arriver avec les bénéfices ou non (trandcution ou induction)

Expliquer le working set != training set (working set == 0 => classic SVM)
1) petits rappels de comment fonctionne la svm avec lien vers les notebooks et 
l'article sur les SVM
2) Introduction sur l'interet de les rendre semi-supervisées

Deuxième partie détaillée sur les SVM semi-supervisées

3) Description mathématique de la SVM semi-supervisée par rapport à une autre (premier article
4) Codage d'une fonction SVM semi-supervisées --> a réutiliser
5) Voir si on peut avoir la même en scikit-learn

Troisième partie sur un cas concret avec un dataset semi-supervisé
1) Analyse des deux méthodes

Quatrième partie sur les bénéfices et limites de cette méthode
1) Limite: pas de possibilité de faire avec de nouveaux points, car il faudrait tout 
recalculer à chaque fois --> mais une nouvelle discipline émerge pour le faire online
(deuxième article)

Conclusion en ouverture avec d'autres types d'algorithmes semi-supervisés
Ouverture sur la manière humaine de faire du semi supervisé

Sources: 

https://en.wikipedia.org/wiki/Semi-supervised_learning
https://en.wikipedia.org/wiki/Transduction_%28machine_learning%29